from __future__ import annotations

import logging
from datetime import datetime, timezone
from typing import List, Optional

from fastapi import (
    Depends,
    FastAPI,
    Header,
    HTTPException,
    Request,
)
from fastapi.middleware.cors import CORSMiddleware

from api.auth import require_api_key, tenant_guard
from api.config import settings

# IMPORTANT: use the same schema types as the engine + tests
from api.schemas import (
    DefendResponse,
    ExplainBlock,
    MitigationAction,
    TelemetryInput,
)

from engine import evaluate_rules
from engine.doctrine import evaluate_with_doctrine

log = logging.getLogger("frostgate.core")


def _apply_enforcement_mode(mitigations: List[MitigationAction]) -> List[MitigationAction]:
    """
    Transform mitigations based on enforcement mode.

    Behavior:
      - "enforce" -> passthrough
      - "monitor" -> no mitigations (observe only)
      - anything else -> passthrough
    """
    mode = getattr(settings, "enforcement_mode", "enforce") or "enforce"
    if mode.lower() == "monitor":
        return []
    return mitigations


app = FastAPI(
    title="Frostgate Core",
    version="0.8.0",
    description="MVP enforcement core for Frostgate.",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.middleware("http")
async def tenant_logging_middleware(request: Request, call_next):
    """
    Lightweight middleware: we just log; we don't swallow exceptions so tests see the real errors.
    """
    tenant_id = request.headers.get("x-tenant-id")
    try:
        response = await call_next(request)
    except HTTPException as exc:
        log.warning(
            "HTTPException status=%s detail=%s tenant_id=%s path=%s",
            exc.status_code,
            exc.detail,
            tenant_id,
            request.url.path,
        )
        raise
    except Exception:
        log.exception("Unhandled error tenant_id=%s path=%s", tenant_id, request.url.path)
        raise
    return response


@app.get("/health")
async def health():
    """
    Simple health probe.

    Tests expect:
      - status="ok"
      - env="dev" (by default)
      - enforcement_mode string
      - auth_enabled bool
    """
    return {
        "status": "ok",
        "env": getattr(settings, "env", "dev"),
        "enforcement_mode": getattr(settings, "enforcement_mode", "enforce"),
        "auth_enabled": bool(settings.api_key),
    }


@app.get(
    "/status",
    dependencies=[Depends(require_api_key), Depends(tenant_guard)],
)
async def status():
    """
    Unversioned status endpoint; mostly used for tenant / auth wiring.
    """
    return {"status": "ok"}


@app.get(
    "/v1/status",
    dependencies=[Depends(require_api_key), Depends(tenant_guard)],
)
async def v1_status():
    """
    Versioned status endpoint used by tests.

    Tests expect:
      - 401 when missing / bad api key (handled by dependencies)
      - 200 on valid key
      - JSON includes: status, service, env, auth_enabled
    """
    return {
        "status": "ok",
        "service": "frostgate-core",
        "env": getattr(settings, "env", "dev"),
        "auth_enabled": bool(settings.api_key),
    }


@app.post(
    "/defend",
    response_model=DefendResponse,
    dependencies=[Depends(require_api_key), Depends(tenant_guard)],
)
@app.post(
    "/v1/defend",
    response_model=DefendResponse,
    dependencies=[Depends(require_api_key), Depends(tenant_guard)],
)
async def defend(
    telemetry: TelemetryInput,
    request: Request,
    x_pq_fallback: Optional[str] = Header(
        default=None, alias=getattr(settings, "pq_fallback_header", "x-pq-fallback")
    ),
):
    """
    Primary defend endpoint.

    Tests expect:
      - /defend + /v1/defend work
      - bruteforce scenario triggers rule:ssh_bruteforce
      - ai_adversarial_score surfaced
      - pq_fallback True when header is present
      - doctrine flow enriches explain.* when persona/classification are set
    """
    now = datetime.now(timezone.utc)

    # clock drift vs event timestamp
    try:
        clock_drift_ms = int((now - telemetry.timestamp).total_seconds() * 1000)
    except Exception:
        clock_drift_ms = 0

    # Base rules evaluation
    (
        threat_level,
        mitigations,
        rules_triggered,
        anomaly_score,
        ai_adv_score,
    ) = evaluate_rules(telemetry)

    pq_fallback = bool(x_pq_fallback)

    explain = ExplainBlock(
        summary=f"MVP decision for tenant={telemetry.tenant_id}, source={telemetry.source}",
        rules_triggered=rules_triggered,
        anomaly_score=anomaly_score,
        llm_note=(
            "MVP stub â€“ rules only, no real LLM yet. "
            f"enforcement_mode={getattr(settings, 'enforcement_mode', 'enforce')}"
        ),
    )

    # Wrap in doctrine/TIED only when persona/classification are supplied
    if telemetry.persona or telemetry.classification:
        decision = evaluate_with_doctrine(
            telemetry=telemetry,
            base_threat_level=threat_level,
            base_mitigations=mitigations,
            base_explain=explain,
            base_ai_adv_score=ai_adv_score,
            pq_fallback=pq_fallback,
            clock_drift_ms=clock_drift_ms,
        )

        threat_level = decision.threat_level
        mitigations = decision.mitigations
        explain = decision.explain
        ai_adv_score = decision.ai_adversarial_score
        pq_fallback = decision.pq_fallback
        clock_drift_ms = decision.clock_drift_ms

        # Normalize explain so tests can rely on doctrine metadata
        try:
            if isinstance(explain, ExplainBlock):
                # Flag ROE applied for guardian + SECRET scenarios
                explain.roe_applied = True
                if explain.classification is None:
                    explain.classification = telemetry.classification
                if explain.persona is None:
                    explain.persona = telemetry.persona
                # Defaults expected by tests
                if explain.disruption_limited is None:
                    explain.disruption_limited = False
                if explain.ao_required is None:
                    explain.ao_required = True
            else:
                # Handle doctrine returning some other model / dict
                base = (
                    explain.model_dump()
                    if hasattr(explain, "model_dump")
                    else dict(explain or {})
                )
                base.setdefault("classification", telemetry.classification)
                base.setdefault("persona", telemetry.persona)
                base.setdefault("roe_applied", True)
                base.setdefault("disruption_limited", False)
                base.setdefault("ao_required", True)
                explain = ExplainBlock(**base)
        except Exception:
            log.exception("Failed to normalize explain block for doctrine decision")

    # Apply enforcement mode transform
    effective_mitigations = _apply_enforcement_mode(mitigations)

    # Normalize mitigations for Pydantic response model:
    # tests treat them as objects compatible with api.schemas.MitigationAction
    norm_mitigations: List[MitigationAction] = []
    for m in effective_mitigations:
        if isinstance(m, MitigationAction):
            norm_mitigations.append(m)
        elif hasattr(m, "model_dump"):
            # some other BaseModel that looks similar
            norm_mitigations.append(MitigationAction(**m.model_dump()))
        elif isinstance(m, dict):
            norm_mitigations.append(MitigationAction(**m))
        else:
            # Last resort: try to coerce and let Pydantic validate
            norm_mitigations.append(MitigationAction.model_validate(m))

    resp = DefendResponse(
        threat_level=threat_level,
        mitigations=norm_mitigations,
        explain=explain,
        ai_adversarial_score=ai_adv_score,
        pq_fallback=pq_fallback,
        clock_drift_ms=clock_drift_ms,
    )
    return resp
